{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-nWeJq10U3O"
      },
      "outputs": [],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-community==0.0.19"
      ],
      "metadata": {
        "id": "8QmLd4XE0m9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "id": "GtODFaqa1Awe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-groq"
      ],
      "metadata": {
        "id": "Y8eGVOZ21WDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyngrok"
      ],
      "metadata": {
        "id": "i_BlUgSWBoMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "id": "MqwqcFcT3j7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unstructured"
      ],
      "metadata": {
        "id": "P7nWEz8O4Nrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app_py_content = \"\"\"\n",
        "import os\n",
        "import streamlit as st\n",
        "import time\n",
        "import pickle\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import UnstructuredURLLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "st.title(\"News Article RAG (Retrieval-Augmented Generation) Tool\")\n",
        "st.sidebar.title(\"News Article URLs\")\n",
        "\n",
        "# Sidebar for URLs\n",
        "urls = []\n",
        "for i in range(3):\n",
        "    url = st.sidebar.text_input(f\"URL {i+1}\")\n",
        "    urls.append(url)\n",
        "\n",
        "process_url_clicked = st.sidebar.button(\"Process URLs\")\n",
        "file_path = \"faiss_store.pkl\"\n",
        "\n",
        "main_placeholder = st.empty()\n",
        "\n",
        "# Get Groq API Key from user\n",
        "groq_api_key = st.sidebar.text_input(\"Enter your Groq API Key\", type=\"password\")\n",
        "\n",
        "# Initialize ChatGroq if API key is provided\n",
        "llm = None\n",
        "if groq_api_key:\n",
        "    llm = ChatGroq(\n",
        "        groq_api_key=groq_api_key,\n",
        "        model_name=\"llama-3.3-70b-versatile\"\n",
        "    )\n",
        "\n",
        "if process_url_clicked:\n",
        "    if not groq_api_key:\n",
        "        st.error(\"Please enter your Groq API Key in the sidebar.\")\n",
        "    elif not any(urls):\n",
        "        st.error(\"Please enter at least one URL.\")\n",
        "    else:\n",
        "        # Filter out empty URLs\n",
        "        valid_urls = [url for url in urls if url.strip()]\n",
        "        \n",
        "        try:\n",
        "            # Load data\n",
        "            main_placeholder.text(\"Data Loading...Started...\")\n",
        "            loader = UnstructuredURLLoader(urls=valid_urls)\n",
        "            data = loader.load()\n",
        "            main_placeholder.text(f\"Data Loading...Completed. Loaded {len(data)} documents.\")\n",
        "            \n",
        "            # Split data\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                separators=['\\\\n\\\\n', '\\\\n', '.', ','],\n",
        "                chunk_size=1000\n",
        "            )\n",
        "            docs = text_splitter.split_documents(data)\n",
        "            main_placeholder.text(f\"Text Splitting...Completed. Created {len(docs)} chunks.\")\n",
        "            \n",
        "            # Create embeddings and save to FAISS index\n",
        "            main_placeholder.text(\"Building Embedding Vector...Started...\")\n",
        "            embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "            vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "            main_placeholder.text(\"Embedding Vector Building...Completed.\")\n",
        "            \n",
        "            # Save the FAISS index to a pickle file\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                pickle.dump(vectorstore, f)\n",
        "                \n",
        "            main_placeholder.success(\"Processing complete! FAISS index saved. You can now ask questions.\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            main_placeholder.error(f\"An error occurred: {str(e)}\")\n",
        "            st.error(\"Please check your URLs and try again.\")\n",
        "\n",
        "query = main_placeholder.text_input(\"Ask a question about the articles:\")\n",
        "\n",
        "if query:\n",
        "    if not groq_api_key:\n",
        "        st.error(\"Please enter your Groq API Key in the sidebar.\")\n",
        "    elif os.path.exists(file_path):\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            vectorstore = pickle.load(f)\n",
        "            main_placeholder.info(\"FAISS index loaded. Generating answer...\")\n",
        "            chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
        "            result = chain({\"question\": query})\n",
        "            st.header(\"Answer\")\n",
        "            st.write(result[\"answer\"])\n",
        "            \n",
        "            # Display sources if available\n",
        "            sources = result.get(\"sources\", \"\")\n",
        "            if sources:\n",
        "                st.subheader(\"Sources:\")\n",
        "                st.write(sources)\n",
        "    else:\n",
        "        main_placeholder.warning(\"FAISS index not found. Please process URLs first by clicking 'Process URLs'.\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_py_content)\n",
        "\n",
        "print(\"app.py created successfully.\")"
      ],
      "metadata": {
        "id": "tJy_Iubb7TiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Kill any previously running streamlit processes to ensure a clean start\n",
        "!pkill streamlit\n",
        "\n",
        "# Start streamlit in the background using nohup\n",
        "# stdout and stderr will be redirected to nohup.out\n",
        "# The \"&\" ensures the command runs in the background of the shell\n",
        "command = \"nohup streamlit run app.py --server.port 8502 > nohup.out 2>&1 &\"\n",
        "process = subprocess.Popen(command, shell=True)\n",
        "\n",
        "print(f\"Streamlit app started in background (PID: {process.pid}). Check nohup.out for logs.\")\n",
        "print(\"You can now access your Streamlit app using the ngrok Public URL you received from the next cell.\")"
      ],
      "metadata": {
        "id": "5oU6xKb17Vks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9482b025"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Terminate open tunnels if any exist\n",
        "ngrok.kill()\n",
        "\n",
        "# --- IMPORTANT: PASTE YOUR NGROK AUTH TOKEN HERE ---\n",
        "# Replace \"YOUR_NGROK_AUTH_TOKEN\" with your actual token from ngrok.com\n",
        "# Example: ngrok.set_auth_token(\"2fK4...your_token_here...J7g\")\n",
        "ngrok.set_auth_token(\"390wcRwqWynNXPglxBkdoXAMa7X_XkNjNSvtx9K9SgfrSah2\") # <--- YOUR TOKEN HAS BEEN ADDED HERE\n",
        "\n",
        "# Streamlit will run on port 8502\n",
        "streamlit_port = 8502\n",
        "\n",
        "# Open a tunnel to the Streamlit port\n",
        "tunnel = ngrok.connect(streamlit_port)\n",
        "print(f\"Streamlit Public URL: {tunnel.public_url}\")\n",
        "print(\"Access your Streamlit app using the URL above.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
